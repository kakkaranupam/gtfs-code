{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required to setup DB and consume GTFS static data\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from mysql.connector import errorcode\n",
    "from mysql.connector.constants import ClientFlag\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "STATIC_CSV = \"static_.csv\"\n",
    "DB_CSV = \"db_.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeScriptsFromFile(filename, cursor):\n",
    "    # Open and read the file as a single buffer\n",
    "    fd = open(filename, 'r')\n",
    "    sqlFile = fd.read()\n",
    "    fd.close()\n",
    "\n",
    "    # all SQL commands (split on ';')\n",
    "    sqlCommands = sqlFile.split(';')\n",
    "\n",
    "    # Execute every command from the input file\n",
    "    for command in sqlCommands:\n",
    "        # This will skip and report errors\n",
    "        # For example, if the tables do not yet exist, this will skip over\n",
    "        # the DROP TABLE commands\n",
    "        try:\n",
    "            cursor.execute(command)\n",
    "        except mysql.connector.Error as error:\n",
    "            print(\"Error occurred while executing script : \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Tables and Indexes\n",
    "\n",
    "def db_setup(filepath, tab=True, idx=False):\n",
    "    connection = mysql.connector.connect(host='localhost', user='root', password='admin')\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        print(\"FILEPATH received : \", filepath)\n",
    "        createtab_file = filepath + \"create-tables.sql\"\n",
    "        createidx_file = filepath + \"create-index.sql\"\n",
    "        \n",
    "        if(tab):\n",
    "            executeScriptsFromFile(createtab_file, cursor)\n",
    "            print(\"TABLES CREATED ...\")\n",
    "            connection.commit()\n",
    "        \n",
    "        if(idx):\n",
    "            executeScriptsFromFile(createidx_file, cursor)\n",
    "            print(\"INDEXES CREATED ...\")\n",
    "            connection.commit()\n",
    "    \n",
    "    except mysql.connector.Error as error:\n",
    "        connection.rollback() #rollback if any exception occured\n",
    "        print(\"The following error has occurred ... \".format(error))\n",
    "\n",
    "    finally:\n",
    "        #closing database connection.\n",
    "        if(connection.is_connected()):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"DB Setup complete. MySQL connection is closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_tables(path, folder, date):\n",
    "    filepath = \"\\'\" + path + folder + \"/\"\n",
    "    \n",
    "    # Agency\n",
    "    filename = \"agency.txt'\"\n",
    "    tablename = \"gtfs.agency\"\n",
    "    print(filepath)\n",
    "    print(filename)\n",
    "    print(tablename)\n",
    "    bulk_ins(filepath, filename, tablename)\n",
    "    \n",
    "    # Calendar_Dates\n",
    "    filename = \"calendar_dates.txt'\"\n",
    "    tablename = \"gtfs.calendar_dates\"\n",
    "    bulk_ins(filepath, filename, tablename)\n",
    "    \n",
    "    # Routes\n",
    "    filename = \"routes.txt'\"\n",
    "    tablename = \"gtfs.routes\"\n",
    "    bulk_ins(filepath, filename, tablename)\n",
    "    \n",
    "    # Shapes\n",
    "    filename = \"shapes.txt'\"\n",
    "    tablename = \"gtfs.shapes\"\n",
    "    bulk_ins(filepath, filename, tablename)\n",
    "    \n",
    "    # Stop_Times\n",
    "    filename = \"stop_times.txt'\"\n",
    "    tablename = \"gtfs.stop_times\"\n",
    "    bulk_ins(filepath, filename, tablename, date)\n",
    "    \n",
    "    #Stops\n",
    "    filename = \"stops.txt'\"\n",
    "    tablename = \"gtfs.stops\"\n",
    "    bulk_ins(filepath, filename, tablename)\n",
    "    \n",
    "    #Transfers\n",
    "    filename = \"transfers.txt'\"\n",
    "    tablename = \"gtfs.transfers\"\n",
    "    bulk_ins(filepath, filename, tablename)\n",
    "    \n",
    "    #Trips\n",
    "    filename = \"trips.txt'\"\n",
    "    tablename = \"gtfs.trips\"\n",
    "    bulk_ins(filepath, filename, tablename, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_ins(filepath, filename, tablename, date=None):\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host='localhost', database='gtfs', user='root', \\\n",
    "                                             password='admin', client_flags=[ClientFlag.LOCAL_FILES])\n",
    "        print(\"Connected to DB ...\", ClientFlag.LOCAL_FILES)\n",
    "        \n",
    "        # Create cursor and execute Load SQL\n",
    "        autoc_sql = \"SET autocommit=0;\"\n",
    "        ucheck_sql = \"SET unique_checks=0;\"\n",
    "        fcheck_sql = \"set foreign_key_checks=0;\"\n",
    "        logcheck_sql = \"set sql_log_bin=0;\"\n",
    "        \n",
    "        load_sql = (\"LOAD DATA LOCAL INFILE \" + filepath + filename +\n",
    "                    \" INTO TABLE \" + tablename +\n",
    "                    \" FIELDS TERMINATED BY ','\"\n",
    "                    \" OPTIONALLY ENCLOSED BY '\\\"'\"\n",
    "                    \" LINES TERMINATED BY '\\\\n'\"\n",
    "                    \" IGNORE 1 LINES\")\n",
    "        \n",
    "        # INSERT DATE IN TABLES STOP_TIMES AND TRIPS\n",
    "        if(tablename == \"gtfs.stop_times\" or tablename == \"gtfs.trips\"):\n",
    "            print(\"DATE VALUE RECEIVED ... \", date)\n",
    "            load_sql = load_sql + \" SET trip_date = '\" + str(date) + \"';\"\n",
    "        else:\n",
    "            load_sql = load_sql + \";\"\n",
    "        \n",
    "        cursor = connection.cursor()\n",
    "        print(\"BULK INS ... \")\n",
    "        print(\"FILEPATH received : \", filepath.strip('\\''))\n",
    "        print(filepath + filename)\n",
    "        print(load_sql)\n",
    "        \n",
    "        cursor.execute(autoc_sql)\n",
    "        cursor.execute(ucheck_sql)\n",
    "        cursor.execute(fcheck_sql)\n",
    "        cursor.execute(logcheck_sql)\n",
    "        \n",
    "        cursor.execute(load_sql)\n",
    "        connection.commit()\n",
    "        print(\"Succuessfully loaded the table \" + tablename + \" from \" + filename.strip('\\'') + \" ... \")\n",
    "    \n",
    "    except mysql.connector.Error as error :\n",
    "        print(cursor.statement)\n",
    "        connection.rollback() #rollback if any exception occured\n",
    "        print(\"Failed inserting record into table \" + tablename + \" from \" + filename.strip('\\'') + \" ... {}\".format(error))\n",
    "        \n",
    "    finally:\n",
    "        #closing database connection.\n",
    "        if(connection.is_connected()):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # FETCH FILES\n",
    "    # READS TWO CSV FILES FROM THE CURRENT WORKING DIRECTORY\n",
    "    # DB_CSV PROVIDES THE PATH WHERE THE TABLE AND INDEX CREATION SCRIPTS ARE KEPT\n",
    "    # STATIC_CSV PROVIDES THE PATH WHERE THE UNZIPPED STATIC DATA IS KEPT\n",
    "    cwd = os.getcwd()\n",
    "    db_csv = cwd.replace(\"\\\\\", \"/\") + \"/\" + DB_CSV\n",
    "    static_csv = cwd.replace(\"\\\\\", \"/\") + \"/\" + STATIC_CSV\n",
    "    \n",
    "    # GET DB SCRIPTS PATH\n",
    "    db_scripts = \"\"\n",
    "    with open(db_csv, \"r\") as file:\n",
    "        next(file)\n",
    "        for row in file:\n",
    "            db_scripts = row.strip().replace(\"\\\\\", \"/\") + \"/\"\n",
    "    \n",
    "#     # SETUP DB\n",
    "#     db_setup(db_scripts, tab=True, idx=False)\n",
    "    \n",
    "#     # DUMP DATA TO DB\n",
    "#     dataset_path = \"\"\n",
    "#     folder_name = \"\"\n",
    "#     folder_date = \"\"\n",
    "#     with open(static_csv, \"r\") as file:\n",
    "#         next(file)\n",
    "#         for row in file:\n",
    "#             row = row.strip().split(\",\")\n",
    "#             dataset_path = row[0].replace(\"\\\\\", \"/\") + \"/\"\n",
    "#             folder_name = row[1]\n",
    "#             folder_date = row[2]\n",
    "#             all_tables(dataset_path, folder_name, folder_date)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Segregate Index Creation for the DB as it takes up a lot of time\n",
    "# # Run after all data has been inserted\n",
    "\n",
    "# # FETCH FILES\n",
    "# cwd = os.getcwd()\n",
    "# db_csv = cwd.replace(\"\\\\\", \"/\") + \"/\" + DB_CSV\n",
    "# static_csv = cwd.replace(\"\\\\\", \"/\") + \"/\" + STATIC_CSV\n",
    "\n",
    "# # GET DB SCRIPTS PATH\n",
    "# db_scripts = \"\"\n",
    "# with open(db_csv, \"r\") as file:\n",
    "#     next(file)\n",
    "#     for row in file:\n",
    "#         db_scripts = row.strip().replace(\"\\\\\", \"/\") + \"/\"\n",
    "# db_setup(db_scripts, tab=False, idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a set of usable trip and service ids from the DB\n",
    "def push_routes(filepath):\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host='localhost', database='gtfs', user='root', \\\n",
    "                                             password='admin', client_flags=[ClientFlag.LOCAL_FILES])\n",
    "        print(\"Connected to DB ...\", ClientFlag.LOCAL_FILES)\n",
    "        \n",
    "        #\n",
    "        sel_sql = ( \" SELECT DISTINCT ROUTE_SHORT_NAME, \"\n",
    "                \" CASE ROUTE_TYPE \"\n",
    "                \" WHEN '0' THEN 'TRAM'\"\n",
    "                \" WHEN '1' THEN 'SUBWAY'\"\n",
    "                \" WHEN '2' THEN 'RAIL'\"\n",
    "                \" WHEN '3' THEN 'BUS'\"\n",
    "                \" WHEN '4' THEN 'FERRY'\"\n",
    "                \" END AS ROUTE_TYPE\"\n",
    "                \" FROM GTFS.ROUTES ORDER BY ABS(ROUTE_SHORT_NAME), ROUTE_TYPE;\" )\n",
    "        \n",
    "        cursor = connection.cursor()\n",
    "        print(\"push_routes() ... \")\n",
    "        print(\"FILEPATH received : \", filepath)\n",
    "        print(sel_sql)\n",
    "        cursor.execute(sel_sql)\n",
    "        all_rows = cursor.fetchall()\n",
    "        \n",
    "        with open(filepath + 'routes_list.csv', 'w') as myfile:\n",
    "            for row in all_rows:\n",
    "                myfile.write(row[0] + \",\" + row[1] + \"\\n\")\n",
    "            print(\"Data write success ... \")\n",
    "            print(\"Please check CSV file ROUTES.CSV at \" + filepath)\n",
    "            \n",
    "#         with open(filepath + 'routes_list.csv', 'w') as myfile:\n",
    "#             wr = csv.writer(myfile)\n",
    "#             for row in all_rows:\n",
    "#                 wr.writerow(row)\n",
    "#             print(\"Data write success ... \")\n",
    "#             print(\"Please check CSV file ROUTES.CSV at \" + filepath)\n",
    "    \n",
    "    except mysql.connector.Error as error :\n",
    "        print(cursor.statement)\n",
    "        connection.rollback() #rollback if any exception occured\n",
    "        print(\"Failed fetching data from GTFS.ROUTES ... {}\".format(error))\n",
    "        \n",
    "    finally:\n",
    "        #closing database connection.\n",
    "        if(connection.is_connected()):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kakka\\Documents\\GTFS_\\code\n",
      "Connected to DB ... 128\n",
      "push_routes() ... \n",
      "FILEPATH received :  C:/Users/kakka/Documents/GTFS_/code/\n",
      " SELECT DISTINCT ROUTE_SHORT_NAME,  CASE ROUTE_TYPE  WHEN '0' THEN 'TRAM' WHEN '1' THEN 'SUBWAY' WHEN '2' THEN 'RAIL' WHEN '3' THEN 'BUS' WHEN '4' THEN 'FERRY' END AS ROUTE_TYPE FROM GTFS.ROUTES ORDER BY ABS(ROUTE_SHORT_NAME), ROUTE_TYPE;\n",
      "Data write success ... \n",
      "Please check CSV file ROUTES.CSV at C:/Users/kakka/Documents/GTFS_/code/\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "# GENERATE ROUTE DETAILS FOR USER\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "push_routes(cwd.replace(\"\\\\\", \"/\") + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required to parse GTFS real-time feed\n",
    "from google.transit import gtfs_realtime_pb2\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ THE SET OF TRANSIT LINES FOR WHICH THE USER WANTS TO EXTRACT STOP TIME DETAILS\n",
    "def read_userpref(filepath):\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host='localhost', database='gtfs', user='root', \\\n",
    "                                             password='admin', client_flags=[ClientFlag.LOCAL_FILES])\n",
    "        print(\"Connected to DB ...\", ClientFlag.LOCAL_FILES)\n",
    "        \n",
    "        # Open and read the file as a single buffer\n",
    "        fd = open(filepath + 'user_routes.csv', 'r')\n",
    "        usrFile = fd.read()\n",
    "        fd.close()\n",
    "        \n",
    "        lines = usrFile.split(\"\\n\")\n",
    "        print(lines)\n",
    "        \n",
    "        routes = []\n",
    "\n",
    "        sel_sql = ( \" SELECT DISTINCT ROUTE_ID, ROUTE_TYPE, ROUTE_SHORT_NAME\"\n",
    "                    \" FROM GTFS.ROUTES\"\n",
    "                    \" WHERE ROUTE_TYPE = %s\"\n",
    "                    \" AND ROUTE_SHORT_NAME = %s\"\n",
    "                    \" ORDER BY ROUTE_ID;\")\n",
    "        \n",
    "        cursor = connection.cursor()\n",
    "        print(\"read_userpref() ... \")\n",
    "        print(\"FILEPATH received : \", filepath)\n",
    "        print(sel_sql)\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.split(',')\n",
    "            print(line)\n",
    "            # REVERSE MAP ROUTE TYPE\n",
    "#             \" WHEN '0' THEN 'TRAM'\"\n",
    "#             \" WHEN '1' THEN 'SUBWAY'\"\n",
    "#             \" WHEN '2' THEN 'RAIL'\"\n",
    "#             \" WHEN '3' THEN 'BUS'\"\n",
    "#             \" WHEN '4' THEN 'FERRY'\"\n",
    "            if line[1] == 'TRAM':\n",
    "                line[1] = 0\n",
    "            elif line[1] == 'SUBWAY':\n",
    "                line[1] = 1\n",
    "            elif line[1] == 'RAIL':\n",
    "                line[1] = 2\n",
    "            elif line[1] == 'BUS':\n",
    "                line[1] = 3\n",
    "            elif line[1] == 'FERRY':\n",
    "                line[1] = 4\n",
    "            cursor.execute(sel_sql, (line[1], line[0]))\n",
    "            routes.append([r for r in cursor.fetchall()])\n",
    "            \n",
    "        return routes\n",
    "    \n",
    "    except mysql.connector.Error as error :\n",
    "        print(cursor.statement)\n",
    "        connection.rollback() #rollback if any exception occured\n",
    "        print(\"Failed inserting record into table \" + tablename + \" from \" + filename + \" ... {}\".format(error))\n",
    "        \n",
    "    finally:\n",
    "        #closing database connection.\n",
    "        if(connection.is_connected()):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kakka\\Documents\\GTFS_\\code\n",
      "Connected to DB ... 128\n",
      "['1,BUS', '1,FERRY', '1,TRAM', '19,BUS', '19,FERRY', '19,TRAM']\n",
      "read_userpref() ... \n",
      "FILEPATH received :  C:/Users/kakka/Documents/GTFS_/code/\n",
      " SELECT DISTINCT ROUTE_ID, ROUTE_TYPE, ROUTE_SHORT_NAME FROM GTFS.ROUTES WHERE ROUTE_TYPE = %s AND ROUTE_SHORT_NAME = %s ORDER BY ROUTE_ID;\n",
      "['1', 'BUS']\n",
      "['1', 'FERRY']\n",
      "['1', 'TRAM']\n",
      "['19', 'BUS']\n",
      "['19', 'FERRY']\n",
      "['19', 'TRAM']\n",
      "MySQL connection is closed\n",
      "[[(188, 3, '1'), (211, 3, '1'), (1063, 3, '1'), (1744, 3, '1'), (2644, 3, '1'), (6731, 3, '1'), (7170, 3, '1'), (19413, 3, '1'), (32759, 3, '1'), (36962, 3, '1'), (41487, 3, '1'), (45366, 3, '1'), (45413, 3, '1'), (45415, 3, '1'), (52890, 3, '1'), (52901, 3, '1'), (52914, 3, '1'), (54174, 3, '1'), (54278, 3, '1'), (54549, 3, '1'), (54567, 3, '1'), (57599, 3, '1'), (57606, 3, '1'), (57610, 3, '1'), (57656, 3, '1'), (57689, 3, '1'), (57757, 3, '1'), (58941, 3, '1'), (59833, 3, '1'), (60805, 3, '1'), (61331, 3, '1'), (61767, 3, '1'), (61784, 3, '1'), (61933, 3, '1'), (61942, 3, '1'), (61944, 3, '1'), (62272, 3, '1')], [(57850, 4, '1')], [(59297, 0, '1'), (60662, 0, '1')], [(7213, 3, '19'), (42296, 3, '19'), (57580, 3, '19'), (57792, 3, '19'), (62392, 3, '19')], [(18931, 4, '19')], [(60664, 0, '19'), (62498, 0, '19')]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Read User Input for lines from a CSV and FETCH THE CORRESPONDING TRIP UPDATE DETAILS FROM THE REALTIME FEED\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "user_routes = read_userpref(cwd.replace(\"\\\\\", \"/\") + \"/\")\n",
    "print(user_routes)\n",
    "all_tus = []\n",
    "\n",
    "feed = gtfs_realtime_pb2.FeedMessage()\n",
    "response = requests.get('http://gtfs.ovapi.nl/nl/tripUpdates.pb')\n",
    "\n",
    "if(response.status_code == 200):\n",
    "    feed.ParseFromString(response.content)\n",
    "    ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    for entity in feed.entity:\n",
    "      if entity.HasField('trip_update'):\n",
    "        for ur in user_routes:\n",
    "            if(entity.trip_update.trip.route_id == str(ur[0])):\n",
    "                print(\"entity.id --- \", entity.id)\n",
    "                for x in entity.trip_update.stop_time_update:\n",
    "                    all_tus.append((entity.id, entity.trip_update.trip.route_id, ur[2], ur[1], entity.trip_update.trip.trip_id, \\\n",
    "                                    entity.trip_update.trip.direction_id, entity.trip_update.trip.start_date, \\\n",
    "                                    entity.trip_update.trip.start_time, x.stop_sequence, x.stop_id, x.arrival.time, \\\n",
    "                                    x.arrival.delay, x.departure.time, x.departure.delay, ts))\n",
    "else:\n",
    "    print(\"ERROR FETCHING REALTIME DATA FROM THE gtfs.ovapi.nl server\")\n",
    "    print(response.reason)\n",
    "\n",
    "print(len(all_tus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
